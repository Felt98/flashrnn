{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from flashrnn.config import FlashRNNConfig\n",
    "from flashrnn.flashrnn import _zero_state,flashrnn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_dtype_to_str(dtype: torch.dtype):\n",
    "    if dtype == torch.float:\n",
    "        return \"float32\"\n",
    "    else:\n",
    "        return str(dtype)[6:]\n",
    "\n",
    "def create_inputs(\n",
    "    batch_size: int,\n",
    "    sequence_size: int,\n",
    "    num_heads: int,\n",
    "    head_dim: int,\n",
    "    function: str,\n",
    "    create_states: bool = True,\n",
    "    dtype: torch.dtype = torch.float16,\n",
    "    device=\"cuda\",\n",
    "    **kwargs,\n",
    "):\n",
    "    cfg = FlashRNNConfig(\n",
    "        batch_size=batch_size,\n",
    "        num_heads=num_heads,\n",
    "        function=function,\n",
    "        head_dim=head_dim,\n",
    "        dtype=torch_dtype_to_str(dtype),\n",
    "    )\n",
    "\n",
    "    num_gates_w = cfg.num_gates_w\n",
    "    num_gates_r = cfg.num_gates_r\n",
    "    num_gates_t = cfg.num_gates_t\n",
    "\n",
    "    Wx = torch.randn(\n",
    "        [batch_size, sequence_size, num_gates_w, num_heads, head_dim],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    R = torch.randn(\n",
    "        [num_gates_r, num_heads, head_dim, head_dim],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    ) / head_dim ** (0.5)\n",
    "    b = torch.randn(\n",
    "        [num_gates_t, num_heads, head_dim],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    states = _zero_state(cfg, Wx)\n",
    "    assert states.dtype == dtype\n",
    "\n",
    "    if create_states:\n",
    "        return Wx, states, R, b\n",
    "    else:\n",
    "        return Wx, R, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "B = 1\n",
    "S = 512\n",
    "# NH = 4\n",
    "# DH = 64\n",
    "NH = 1\n",
    "DH = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fp64 = create_inputs(\n",
    "    batch_size=B,\n",
    "    sequence_size=S,\n",
    "    num_heads=NH,\n",
    "    head_dim=DH,\n",
    "    function=\"lstm\",\n",
    "    dtype=torch.float64,\n",
    "    create_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_target = torch.bfloat16\n",
    "# inputs_dtype =  create_inputs(\n",
    "#     batch_size=B,\n",
    "#     sequence_size=S,\n",
    "#     num_heads=NH,\n",
    "#     head_dim=DH,\n",
    "#     function=\"lstm\",\n",
    "#     dtype=dtype_target,\n",
    "#     create_states=False,\n",
    "# )\n",
    "inputs_dtype = (x.clone().to(dtype_target) for x in inputs_fp64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function:  lstm\n",
      "backend:  vanilla\n",
      "Wx:  torch.Size([512, 1, 4, 1, 768])\n",
      "R:  torch.Size([1, 768, 4, 768])\n",
      "b:  torch.Size([4, 1, 768])\n",
      "input states:  torch.Size([1, 1, 2, 1, 768])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res_fp64 = \u001b[43mflashrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs_fp64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlstm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvanilla\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/second/qinhaoping/repo/flashRNN/main/flashrnn/debug/../flashrnn/flashrnn.py:332\u001b[39m, in \u001b[36mflashrnn\u001b[39m\u001b[34m(Wx, R, b, states, function, config, backend, dtype)\u001b[39m\n\u001b[32m    330\u001b[39m R_list = [R]\n\u001b[32m    331\u001b[39m b_list = [b]\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m h, last_h, out = \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mWx_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mR_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mh: \u001b[39m\u001b[33m\"\u001b[39m, h.shape)\n\u001b[32m    339\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mlast_h: \u001b[39m\u001b[33m\"\u001b[39m, last_h.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/second/qinhaoping/repo/flashRNN/main/flashrnn/debug/../flashrnn/flashrnn.py:163\u001b[39m, in \u001b[36m_get_kernel.<locals>.fn\u001b[39m\u001b[34m(Wx_list, states, R_list, b_list, **kwargs)\u001b[39m\n\u001b[32m    161\u001b[39m R = R_list[\u001b[32m0\u001b[39m]\n\u001b[32m    162\u001b[39m b = b_list[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflashrnn_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mWx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpointwise_forward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflashrnn_pointwise_function_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/second/qinhaoping/repo/flashRNN/main/flashrnn/debug/../flashrnn/vanilla/__init__.py:38\u001b[39m, in \u001b[36mflashrnn_forward\u001b[39m\u001b[34m(Wx, states, R, b, pointwise_forward, constants)\u001b[39m\n\u001b[32m     35\u001b[39m num_heads = R.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     36\u001b[39m head_dim = R.shape[\u001b[32m3\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m batch_dim == states.shape[\u001b[32m1\u001b[39m]\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# g = torch.zeros(\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m#     [sequence_dim + 1, batch_dim, num_gates_t, num_heads, head_dim],\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m#     device=Wx.device,\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m#     dtype=Wx.dtype,\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     46\u001b[39m states_all = torch.zeros(\n\u001b[32m     47\u001b[39m     [sequence_dim + \u001b[32m1\u001b[39m, batch_dim, num_states, num_heads, head_dim],\n\u001b[32m     48\u001b[39m     device=Wx.device,\n\u001b[32m     49\u001b[39m     dtype=Wx.dtype,\n\u001b[32m     50\u001b[39m )\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "res_fp64 = flashrnn(*inputs_fp64, function=\"lstm\", backend=\"vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dtype = flashrnn(*inputs_dtype, function=\"lstm\", backend=\"cuda_fused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_np = res_fp64[0].cpu().numpy()\n",
    "target_np = res_dtype[0].to(dtype=torch.float64).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_np[0].reshape(B, S, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors_c_h(baseline, target, sequence_length, batch_size):\n",
    "    bl_h = baseline[0].reshape(batch_size, sequence_length, -1)\n",
    "    bl_c = baseline[1].reshape(batch_size, sequence_length, -1)\n",
    "\n",
    "    tg_h = target[0].reshape(batch_size, sequence_length, -1)\n",
    "    tg_c = target[1].reshape(batch_size, sequence_length, -1)\n",
    "\n",
    "    c_err = np.abs(bl_c - tg_c)\n",
    "    h_err = np.abs(bl_h - tg_h)\n",
    "    return c_err, h_err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_err, h_err = compute_errors_c_h(baseline_np, target_np, S, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot.diff_lineplot import plot_error_statistics_over_time_single, plot_error_statistics_over_time_per_batchhead\n",
    "from flashrnn.speed_experiments.plot_config import (\n",
    "        FONTSIZE,\n",
    "        FONTSIZE_SMALL,\n",
    "        FONTSIZE_TICKS,\n",
    "        FIGSIZE,\n",
    "        style_dict,\n",
    "        save_path,\n",
    "    )\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(\n",
    "    rc={\n",
    "        \"text.usetex\": True,\n",
    "        \"font.size\": FONTSIZE,\n",
    "        \"axes.labelsize\": FONTSIZE,\n",
    "        \"legend.fontsize\": FONTSIZE_SMALL,\n",
    "        \"xtick.labelsize\": FONTSIZE_TICKS,\n",
    "        \"ytick.labelsize\": FONTSIZE_TICKS,\n",
    "        \"axes.titlesize\": FONTSIZE,\n",
    "        \"lines.markersize\": 4.0,  # * default: 6.0\n",
    "    }\n",
    "):\n",
    "    fig = plot_error_statistics_over_time_per_batchhead(\n",
    "        errors=h_err,\n",
    "        percentiles=[50, 90, 100],\n",
    "        title=\"LSTM Hidden State Error\",\n",
    "        add_mean=True,\n",
    "        ema_alpha=0.7,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig[0].savefig(\"./lstm_hidden_state_error.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mpl.rc_context(\n",
    "#     rc={\n",
    "#         \"text.usetex\": True,\n",
    "#         \"font.size\": FONTSIZE,\n",
    "#         \"axes.labelsize\": FONTSIZE,\n",
    "#         \"legend.fontsize\": FONTSIZE_SMALL,\n",
    "#         \"xtick.labelsize\": FONTSIZE_TICKS,\n",
    "#         \"ytick.labelsize\": FONTSIZE_TICKS,\n",
    "#         \"axes.titlesize\": FONTSIZE,\n",
    "#         \"lines.markersize\": 4.0,  # * default: 6.0\n",
    "#     }\n",
    "# ):\n",
    "#     fig = plot_error_statistics_over_time_per_batchhead(\n",
    "#         errors=c_err,\n",
    "#         percentiles=[50, 90, 100],\n",
    "#         title=\"LSTM Cell State Error\",\n",
    "#         add_mean=True,\n",
    "#         ema_alpha=0.5,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
