{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from flashrnn import FlashRNNConfig, flashrnn\n",
    "from flashrnn.flashrnn import _zero_state\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_dtype_to_str(dtype: torch.dtype):\n",
    "    if dtype == torch.float:\n",
    "        return \"float32\"\n",
    "    else:\n",
    "        return str(dtype)[6:]\n",
    "\n",
    "def create_inputs(\n",
    "    batch_size: int,\n",
    "    sequence_size: int,\n",
    "    num_heads: int,\n",
    "    head_dim: int,\n",
    "    function: str,\n",
    "    create_states: bool = True,\n",
    "    dtype: torch.dtype = torch.float16,\n",
    "    device=\"cuda\",\n",
    "    **kwargs,\n",
    "):\n",
    "    cfg = FlashRNNConfig(\n",
    "        batch_size=batch_size,\n",
    "        num_heads=num_heads,\n",
    "        function=function,\n",
    "        head_dim=head_dim,\n",
    "        dtype=torch_dtype_to_str(dtype),\n",
    "    )\n",
    "\n",
    "    num_gates_w = cfg.num_gates_w\n",
    "    num_gates_r = cfg.num_gates_r\n",
    "    num_gates_t = cfg.num_gates_t\n",
    "\n",
    "    Wx = torch.randn(\n",
    "        [batch_size, sequence_size, num_gates_w, num_heads, head_dim],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    R = torch.randn(\n",
    "        [num_gates_r, num_heads, head_dim, head_dim],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    ) / head_dim ** (0.5)\n",
    "    b = torch.randn(\n",
    "        [num_gates_t, num_heads, head_dim],\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    states = _zero_state(cfg, Wx)\n",
    "    assert states.dtype == dtype\n",
    "\n",
    "    if create_states:\n",
    "        return Wx, states, R, b\n",
    "    else:\n",
    "        return Wx, R, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "B = 1\n",
    "S = 512\n",
    "# NH = 4\n",
    "# DH = 64\n",
    "NH = 1\n",
    "DH = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_fp64 = create_inputs(\n",
    "    batch_size=B,\n",
    "    sequence_size=S,\n",
    "    num_heads=NH,\n",
    "    head_dim=DH,\n",
    "    function=\"lstm\",\n",
    "    dtype=torch.float64,\n",
    "    create_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_target = torch.bfloat16\n",
    "# inputs_dtype =  create_inputs(\n",
    "#     batch_size=B,\n",
    "#     sequence_size=S,\n",
    "#     num_heads=NH,\n",
    "#     head_dim=DH,\n",
    "#     function=\"lstm\",\n",
    "#     dtype=dtype_target,\n",
    "#     create_states=False,\n",
    "# )\n",
    "inputs_dtype = (x.clone().to(dtype_target) for x in inputs_fp64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fp64 = flashrnn(*inputs_fp64, function=\"lstm\", backend=\"vanilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dtype = flashrnn(*inputs_dtype, function=\"lstm\", backend=\"cuda_fused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_np = res_fp64[0].cpu().numpy()\n",
    "target_np = res_dtype[0].to(dtype=torch.float64).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_np[0].reshape(B, S, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors_c_h(baseline, target, sequence_length, batch_size):\n",
    "    bl_h = baseline[0].reshape(batch_size, sequence_length, -1)\n",
    "    bl_c = baseline[1].reshape(batch_size, sequence_length, -1)\n",
    "\n",
    "    tg_h = target[0].reshape(batch_size, sequence_length, -1)\n",
    "    tg_c = target[1].reshape(batch_size, sequence_length, -1)\n",
    "\n",
    "    c_err = np.abs(bl_c - tg_c)\n",
    "    h_err = np.abs(bl_h - tg_h)\n",
    "    return c_err, h_err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_err, h_err = compute_errors_c_h(baseline_np, target_np, S, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot.diff_lineplot import plot_error_statistics_over_time_single, plot_error_statistics_over_time_per_batchhead\n",
    "from flashrnn.speed_experiments.plot_config import (\n",
    "        FONTSIZE,\n",
    "        FONTSIZE_SMALL,\n",
    "        FONTSIZE_TICKS,\n",
    "        FIGSIZE,\n",
    "        style_dict,\n",
    "        save_path,\n",
    "    )\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(\n",
    "    rc={\n",
    "        \"text.usetex\": True,\n",
    "        \"font.size\": FONTSIZE,\n",
    "        \"axes.labelsize\": FONTSIZE,\n",
    "        \"legend.fontsize\": FONTSIZE_SMALL,\n",
    "        \"xtick.labelsize\": FONTSIZE_TICKS,\n",
    "        \"ytick.labelsize\": FONTSIZE_TICKS,\n",
    "        \"axes.titlesize\": FONTSIZE,\n",
    "        \"lines.markersize\": 4.0,  # * default: 6.0\n",
    "    }\n",
    "):\n",
    "    fig = plot_error_statistics_over_time_per_batchhead(\n",
    "        errors=h_err,\n",
    "        percentiles=[50, 90, 100],\n",
    "        title=\"LSTM Hidden State Error\",\n",
    "        add_mean=True,\n",
    "        ema_alpha=0.7,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig[0].savefig(\"./lstm_hidden_state_error.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mpl.rc_context(\n",
    "#     rc={\n",
    "#         \"text.usetex\": True,\n",
    "#         \"font.size\": FONTSIZE,\n",
    "#         \"axes.labelsize\": FONTSIZE,\n",
    "#         \"legend.fontsize\": FONTSIZE_SMALL,\n",
    "#         \"xtick.labelsize\": FONTSIZE_TICKS,\n",
    "#         \"ytick.labelsize\": FONTSIZE_TICKS,\n",
    "#         \"axes.titlesize\": FONTSIZE,\n",
    "#         \"lines.markersize\": 4.0,  # * default: 6.0\n",
    "#     }\n",
    "# ):\n",
    "#     fig = plot_error_statistics_over_time_per_batchhead(\n",
    "#         errors=c_err,\n",
    "#         percentiles=[50, 90, 100],\n",
    "#         title=\"LSTM Cell State Error\",\n",
    "#         add_mean=True,\n",
    "#         ema_alpha=0.5,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt240cu124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
